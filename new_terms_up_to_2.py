import sqlite3
import csv
import re
import pandas as pd

# Intialize Global SQL Objects
conn = sqlite3.connect(':memory:')
cur = conn.cursor()

# Create 4 tables Terms, FragmentsLT3(Fragments less than 3), Type1SearchTerms, Type2SearchTerms
cur.execute('CREATE TABLE Terms (full_normalized text, original text, ID text)')
cur.execute('CREATE TABLE FragmentsLT3 (randr_fragment text, original text, ID text)')
cur.execute('CREATE TABLE TypeSearchTerms (randr_fragment text, randr_fragment_broken text, term_randr_found text, ID text)')

cur.execute('CREATE INDEX idx_terms ON Terms (original, ID)')
cur.execute('CREATE INDEX idx_frag ON FragmentsLT3 (original, ID)')

# Helper to generate SQL LIKE statement from list of terms
# Statement will return from from Terms where a sentence contains every term in list l in no paticular order
# Ex. in: [a, b, c]
#    out: original LIKE '%:a:%' AND original LIKE '%:b:%' original LIKE '%:c:%'
def _make_like(l):
    return ("full_normalized LIKE '%:" + (":%' AND full_normalized LIKE '%:").join(l) + ":%'")

# Helper to generate SQL INTERSECT statement for type 2 terms
# Statement will return all IDs that contain every term in list l at least once
# Ex. in: [a, b, c]
#    out:  SELECT DISTINCT ID FROM Terms WHERE original LIKE '%:a:%' INTERSECT SELECT DISTINCT ID FROM Terms WHERE original LIKE '%:b:%' INTERSECT SELECT DISTINCT ...
def _make_int(l):
    return ("SELECT DISTINCT ID FROM Terms WHERE full_normalized LIKE '%:" + (":%' INTERSECT SELECT DISTINCT ID FROM Terms WHERE full_normalized LIKE '%:").join(l) + ":%'")
def _rem_chars(s, l):
    if l < 0:
        return s
    chars = ['-', '.', '=', '+', '/', ';', '*', '_', ':']
    pieces = s.split(':'+str(l)+':')
    ret = []
    for piece in pieces:
        piece = _rem_chars(piece, l-1)
        if len(piece) > 0 and piece not in chars:
            ret.append(piece)
    return (':'+str(l)+':').join(ret)

# Read in csv generated by terms.py program, INSERT into table Terms
def populate_terms(in_csv):
    for row in csv.reader(open(in_csv, 'r')):
        cur.execute('INSERT INTO Terms VALUES (?, ?, ?)', (row[8], row[7], row[10]))

# Generates table FragmentsLT3 by splitting each DISTINCT full_normalized at all levels >= 3, and
# inserting these pieces (fragments), along with metadata into the table.
# "symbol" terms, pieces that are in all caps at any level i.e. DNA, SQL are also inserted as individual fragments
def populate_fragments():
    cur.execute('SELECT DISTINCT full_normalized, original, ID FROM Terms')
    for row in cur.fetchall():
        strip = row[0].strip(':')
        pieces = re.split(r':([3-9]|[1-9][0-9]+):', strip)
        pieces = list(set(pieces))
        symbols = list(set(filter(lambda x: x.isalpha() and x == x.upper(), re.split(r':[0-9]+:', strip))))
        for piece in pieces:
            piece = _rem_chars(piece, 2)
            if re.search(r'(:0:)|(:1:)|(:2:)', piece):
                cur.execute('INSERT INTO FragmentsLT3 VALUES (?, ?, ?)', (piece, row[1], row[2]))
            two_level = piece.split(':2:')
            for two in two_level:
                if re.search(r'(:0:)|(:1:)|(:2:)', two):
                    cur.execute('INSERT INTO FragmentsLT3 VALUES (?, ?, ?)', (two, row[1], row[2]))
                one_level = two.split(':1:')
                for one in one_level:
                    if re.search(r'(:0:)|(:1:)|(:2:)', one):
                        cur.execute('INSERT INTO FragmentsLT3 VALUES (?, ?, ?)', (one, row[1], row[2]))
        for symbol in symbols:
            cur.execute('INSERT INTO FragmentsLT3 VALUES (?, ?, ?)', (symbol, row[1], row[2]))

# Populates table Type1SearchTerms with type 1 search terms
# Type 1 search terms represent any phrase in which the terms appear in any given order
# Ex. He ate green food. & He ate food, it was green. Should be recognised by the same search terms
def make_type_1():
    cur.execute('SELECT DISTINCT randr_fragment FROM FragmentsLT3')
    for row in cur.fetchall():
        pieces = re.split(r':[1-9][0-9]*:', row[0])
        cur.execute('INSERT INTO TypeSearchTerms SELECT ?, ?, full_normalized, ID FROM Terms WHERE '+_make_like(pieces), (row[0], ' '.join(pieces)))

# Populates table Type2SearchTerms with type 2 search terms
# Type 2 search terms recognize documents that contain a given set of search terms in any given order
# Ex. A book containing the sentences: Jim packed his bag.
#                                     (... 3 lines later ..)
#                                       He walked to school.
# Should be recongnized by the search terms "Jim walked school"
def make_type_2():
    cur.execute('SELECT DISTINCT randr_fragment FROM FragmentsLT3')
    for row in cur.fetchall():
        pieces = re.split(r':[1-9][0-9]*:', row[0])
        pieces = list(set(pieces))
        statement = _make_int(pieces)
        cur.execute(statement)
        for ID in cur.fetchall():
            cur.execute('INSERT INTO TypeSearchTerms VALUES (?, ?, ?, ?)', (row[0], ' '.join(pieces), '', ID[0]))

def new_terms_program(in_csv, out_csv_type_0, out_csv_type_1):
    print("Populating Terms table...")
    populate_terms(in_csv)
    print("DONE")
    print("Populating Fragments table...")
    populate_fragments()
    print("DONE")
    print("Creating Type 1 Terms...")
    make_type_1()
    print("DONE")
    print("Creating Type 2 Terms...")
    make_type_2()
    print("Outputting to CSVs...")
    pd.read_sql(sql='SELECT DISTINCT * FROM FragmentsLT3', con=conn).to_csv(out_csv_type_0, index=False, sep=',', quoting=csv.QUOTE_NONNUMERIC, encoding='utf-8-sig')
    pd.read_sql(sql='SELECT DISTINCT * FROM TypeSearchTerms', con=conn).to_csv(out_csv_type_1, index=False, sep=',', quoting=csv.QUOTE_NONNUMERIC, encoding='utf-8-sig')
    #pd.read_sql(sql='SELECT DISTINCT * FROM Type2SearchTerms', con=conn).to_csv(out_csv_type_2, index=False, sep=',', quoting=csv.QUOTE_NONNUMERIC, encoding='utf-8-sig')
    print("DONE")
    print("FINISHED")

if __name__ == '__main__':
    new_terms_program('terms_full_set.csv', 'type_zero.csv', 'types_one_two.csv')
